#+title: Mini Project 2
#+author: Aatmun Baxi
* Project Statement
** Hypothesis Testing of Standard Assumptions Theoretical Financial Mathematics

In the theory of mathematical finance, it is common to assume the log returns of a stock/index are normally distributed.

Investigate if the log returns of stocks or indexes of your choosing are normally distributed. Some suggestions for exploration include:

1) Test if there are period of times when the log-returns of a stock/index have evidence of normal distribution.
2) Test if removing extremal return data creates a distribution with evidence of being normal.
3) Create a personalized portfolio of stocks with historical log return data that is normally distributed.
4) Test if the portfolio you created in the first mini-project has significant periods of time with evidence of normally distributed log returns.
5) Gather x-number of historical stock data and just perform a normality test on their log return data to see if any of the stocks exhibit evidence of log returns that are normally distributed.


* Data Retrieval

#+begin_src jupyter-python :exports both :session MiniProject2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

%matplotlib inline
sns.set_style("darkgrid")
#+end_src

#+RESULTS:

Because of its high data availability, we choose the S&P 500 to analyze for our index.
#+begin_src jupyter-python :exports both :session MiniProject2
def csv_to_series(csv_path):
    s = pd.read_csv(csv_path)
    s["Date"] = pd.to_datetime(s["Date"])
    s.set_index("Date",inplace = True)
    returns = (s.shift(-1)-s) / s
    returns.columns = [ticker + " Returns" for ticker in s.columns]
    return pd.concat([s, returns],axis=1)

sp500 = csv_to_series("./SP500-returns.csv")
sp500.rename(columns= {"SPYSIM": "SP500", "SPYSIM Returns":"SP500 Returns"},inplace=True)
log_returns = np.log((1+sp500["SP500 Returns"]).dropna())
#+end_src

#+RESULTS:

* Heuristic Checks for Lognormality
As a preliminary look, we can look at the distribution of daily returns.
#+begin_src jupyter-python :exports both :session MiniProject2
log_returns.plot(kind="hist",
                          bins = 100,
                          xlabel="Logdaily Returns",
                          ylabel="Observations",
                          title="Distribution of Logdaily S&P 500 Returns")
#+end_src

#+RESULTS:
:RESULTS:
: <Axes: title={'center': 'Distribution of Logdaily S&P 500 Returns'}, xlabel='Logdaily Returns', ylabel='Observations'>
[[file:./.ob-jupyter/d3d96040bfda34dd4a8ca676cd043ddb8e7835a8.png]]
:END:

A visual inspection is far from sufficient for a test of normality.
We can first "zoom in" to the zero point to viseually cut out the outliers of log returns of absolute magnitude \(> 0.10\).

#+begin_src jupyter-python :exports both :session MiniProject2
log_returns.plot(kind="hist",
                          bins = 100,
                          xlabel="Log Returns",
                          ylabel="Observations",
                          xlim=(-.1,.1),
                          title="Distribution of Logdaily S&P 500 Returns")
#+end_src

#+RESULTS:
:RESULTS:
: <Axes: title={'center': 'Distribution of Logdaily S&P 500 Returns'}, xlabel='Log Returns', ylabel='Observations'>
[[file:./.ob-jupyter/89bcc20773c776222a04ee00d7b5df0fcf488715.png]]
:END:

We first note that the distribution appears negatively skewed, with the left tail being fatter than the right tail.
We can verify this empirically
#+begin_src jupyter-python :exports both :session MiniProject2
log_returns.skew()
#+end_src

#+RESULTS:
: np.float64(-0.43940576052749036)

Indeed, the distribution is negatively skewed.
The value of skewness alone gives us a hint that the data are not normally distributed.

#+begin_src jupyter-python :exports both :session MiniProject2
# pd.DataFrame(log_returns).boxplot()
sns.boxplot(log_returns)
#+end_src

#+RESULTS:
:RESULTS:
: <Axes: ylabel='SP500 Returns'>
[[file:./.ob-jupyter/fe334de74dd34080bd4d07edd7c9b521b3c62303.png]]
:END:

The vast majority of the log return values seem to lie in the interval \((-0.10,0.10)\).
This is the range we will inspect.
#+begin_src jupyter-python :exports both :session MiniProject2
clamped=pd.DataFrame(log_returns[(log_returns <= 0.1) & (log_returns >= -0.1) ])
sns.boxplot(clamped)
#+end_src

#+RESULTS:
:RESULTS:
: <Axes: >
[[file:./.ob-jupyter/5e93f2bc90da8bd2719b0dc12878af0a509e0a7f.png]]
:END:

The boxplot still shows signs of negative skewness, but we can check if the magnitude of skewness is less than what we started with.
#+begin_src jupyter-python :exports both :session MiniProject2
clamped.skew()
#+end_src

#+RESULTS:
: SP500 Returns   -0.330623
: dtype: float64

The skewness does decrease in magnitude, but its value still indicates a distribution far from normal.
It seems daily returns are too negatively skewed to recover a distribution that is normal.

Instead, we can coarsen our return periods to weekly, monthly, and yearly returns to see if they exhibit different behaviours.
We should expect this to be an improvement on log-daily returns, since the reliability of stock returns tends to increase the longer the time period you look at.

#+begin_src jupyter-python :exports both :session MiniProject2
weekly_logs = log_returns.groupby(pd.Grouper(freq="W-MON")).agg("sum")
weekly_logs.plot(kind="hist",bins = 60,
                 title="Weekly log Returns",
                 xlabel="Log Returns")
#+end_src

#+RESULTS:
:RESULTS:
: <Axes: title={'center': 'Weekly log Returns'}, xlabel='Log Returns', ylabel='Frequency'>
[[file:./.ob-jupyter/535d83082e2378e20fc386b198cca1dcf5268ee2.png]]
:END:

#+begin_src jupyter-python :exports both :session MiniProject2
weekly_logs.skew()
#+end_src

#+RESULTS:
: np.float64(-0.8428780928389739)

On the collection of all the data, the skewness of the weekly log returns is less skewed than the daily log returns, but still skewed in the same direction.
We can coarsen the view to further to monthly returns.
#+begin_src jupyter-python :exports both :session MiniProject2
monthly_logs = log_returns.groupby(pd.Grouper(freq="ME")).agg("sum")
monthly_logs.plot(kind="hist",bins = 60,
                 title="Monthly log Returns",
                 xlabel="Log Returns")
#+end_src

#+RESULTS:
:RESULTS:
: <Axes: title={'center': 'Monthly log Returns'}, xlabel='Log Returns', ylabel='Frequency'>
[[file:./.ob-jupyter/dba3aa8a5210f398694841ce08dadbf3d9e7bbc2.png]]
:END:

#+begin_src jupyter-python :exports both :session MiniProject2
monthly_logs.skew()
#+end_src

#+RESULTS:
: np.float64(-0.5649387662902664)

Even monthy returns are negatively skewed.
#+begin_src jupyter-python :exports both :session MiniProject2
yearly_logs = log_returns.groupby(pd.Grouper(freq="YE")).agg("sum")
yearly_logs.plot(kind="hist",bins = 60,
                 title="log Yearly Returns",
                 xlabel="Log Returns")
#+end_src

#+RESULTS:
:RESULTS:
: <Axes: title={'center': 'log Yearly Returns'}, xlabel='Log Returns', ylabel='Frequency'>
[[file:./.ob-jupyter/f8d4426c56599a2559867a4936d2eabc7d3b6861.png]]
:END:

#+begin_src jupyter-python :exports both :session MiniProject2
yearly_logs.skew()
#+end_src

#+RESULTS:
: np.float64(-0.9182998475458627)

Even at time scales such as a year, returns of a diverse portfolio of US stocks shows little evidence of being normal on visual tests.
* Formal Tests for Normality
So far, our tests for normality has been heuristic in nature.
There are formal tests for normality such as she Shapiro-Wilk test, which we can employ.
Below is the resulting \(p\) values extracted from the test, where the null hypothesis is that the data are normally distributed.
#+begin_src jupyter-python :exports both :session MiniProject2
from scipy.stats import shapiro
names = ["Logdaily", "Logweekly","Logmonthly","Logyearly"]
vars = [log_returns,weekly_logs,monthly_logs,yearly_logs]
results = {x[0]: float(shapiro(x[1])[1]) for x in zip(names,vars)}
print(f"Shapiro-Wilk p-values:\n {results}")
#+end_src

#+RESULTS:
: Shapiro-Wilk p-values:
:  {'Logdaily': 3.818543836005726e-93, 'Logweekly': 1.178035812533499e-52, 'Logmonthly': 1.2008592564652523e-28, 'Logyearly': 0.00021204832741650683}
: /nix/store/8f9zfpbmybfl09aq4a9nzp8a9gwgqjbf-python3.12-scipy-1.15.3/lib/python3.12/site-packages/scipy/stats/_axis_nan_policy.py:586: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 35112.
:   res = hypotest_fun_out(*samples, **kwds)
: /nix/store/8f9zfpbmybfl09aq4a9nzp8a9gwgqjbf-python3.12-scipy-1.15.3/lib/python3.12/site-packages/scipy/stats/_axis_nan_policy.py:586: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 7316.
:   res = hypotest_fun_out(*samples, **kwds)

In every performance of the Shapiro-Wilk test, the resulting \(p\) value is decidedly below \(0.05\), so in every case we reject the null hypothesis that the data are normally distributed.

On the other hand, the =normaltest= from =scipy.stats= uses skewness and kurtosis to compare against a normal distribtution.

#+begin_src jupyter-python :exports both :session MiniProject2
from scipy.stats import normaltest
print(f"p-values; skewness-kurtosis test:\n{normaltest(pd.concat([log_returns, weekly_logs, monthly_logs,yearly_logs],axis=1),nan_policy='omit',axis=0).pvalue}")
#+end_src

#+RESULTS:
: p-values; skewness-kurtosis test:
: [0.00000000e+00 0.00000000e+00 2.01874396e-72 5.74204997e-06]

In this test, too, there is sufficient evidence to reject the hypothesis that the data are normaly distributed at all sampled time scales.

* Testing Particular Bull Markets
Because of the pervasive observation that stock returns are negatively skewed, we might have better luck finding evidence of normality of stock returns during bull marketsâ€”periods where the market trends upward without a 20% drop from its high.
Bull markets are usually marked by extended periods of lower volatility, and volatility tends to beget volatility, causing bouts out-of-sample returns that could disrupt a normal distribution.

We first examine the longest bull market in US history: the period between December 1987 and March 2000
#+begin_src jupyter-python :exports both :session MiniProject2
start, end = ("1987-12-01","2000-03-01")
log_returns[start:end].plot(kind="hist",bins=50,xlabel="Log Daily Returns")

#+end_src

#+RESULTS:
:RESULTS:
: <Axes: xlabel='Log Daily Returns', ylabel='Frequency'>
[[file:./.ob-jupyter/4562bfd97122c54278ffd2b558102cb4786104d5.png]]
:END:

Looking at the distribution of daily returns, we can already see a thinning of the tails, though the daily returns still appear negatively distributed.
We investigate the \(p\) value of the formal Shapiro-Wilk test on the monthly returns during this bull market.
#+begin_src jupyter-python :exports both :session MiniProject2
print(f"p = {shapiro(monthly_logs[start:end])[1]}")
#+end_src

#+RESULTS:
: p = 0.08925705296209206

With a tolerance of \(p = 0.05\), there is not sufficient evidence to reject the null hypothesis that the data is normally distributed.
Thus, there is possible evidence of the log monthly returns of the S&P 500 being normally distributed during the 1987-2000 bull market.

Let us investigate the second longest bull market spanning from March 2009 to February 2020.
#+begin_src jupyter-python :exports both :session MiniProject2
start, end = ("2009-03-01", "2020-02-01")
log_returns[start:end].plot(kind="hist",bins=50,xlabel="Log Daily Returns",
                            title="Log Daily Returns Mar 2009-Feb 2020")
#+end_src

#+RESULTS:
:RESULTS:
: <Axes: title={'center': 'Log Daily Returns Mar 2009-Feb 2020'}, xlabel='Log Daily Returns', ylabel='Frequency'>
[[file:./.ob-jupyter/5b4f189bacc8d07a251a1befbe4e44cfb7cc1e16.png]]
:END:

This time, the left tail is much fatter than the previous bull market under examination.
#+begin_src jupyter-python :exports both :session MiniProject2
print(f"p = {shapiro(monthly_logs[start:end])[1]}")
#+end_src

#+RESULTS:
: p = 0.0011705343595598972

As the visual inspection suggested, we cannot conclude normality of the monthly returns in this period.


** Conclusion
We can conclude that it is very difficult to find periods of time and scales of time where stock returns are normally distributed, even when volatility is controlled by using a diversified portfolio.
This suggests that the assumption of normal stock returns used in the Black-Scholes model does not reflect reality.
It still serves the useful purpose of helping extract closed-form equation
* A "Portfolio" with Normal Return
For some commentary, we should not expect it to be easy to construct a portfolio of stocks (i.e. *equities*) with lognormal returns over a significant period of time.
Equities are inherently riskier than other financial assets like bonds, and show fatter tails in distributions of historical returns on virtually all time scales.
One typically reduces the volatility of a portfolio of stocks by allocating to "safer" kinds of stocks (e.g. consumer staples, utilities) or by moving away from stocks altogether and using bonds.
Since we are interested in stocks only, we will work within the confines of equities.

We hypothesize that a diverse portfolio is the wrong way to mine logreturns that might be normal.
Instead, we look at a particular individual stock in the consumer staple sector, Coca-Cola (KO).
#+begin_src jupyter-python :session MiniProject2
ko = csv_to_series("./KO.csv")
log_ko = np.log(1+ko["KO Returns"])
#+end_src

#+RESULTS:

#+begin_src jupyter-python :session MiniProject2
shapiro(log_ko.groupby(pd.Grouper(freq="W-MON")).agg("sum"))
#+end_src

#+RESULTS:
: ShapiroResult(statistic=np.float64(0.9619671474112037), pvalue=np.float64(1.1627666805933354e-28))

#+begin_src jupyter-python :session MiniProject2
p1 = np.log(1+ 0.20*sp500["SP500 Returns"] + 0.40*ko["KO Returns"] + 0.40*xlp["Staples Returns"])
p1[start:end].plot(kind="hist",bins=80)
shapiro(p1[start:end])
#+end_src

#+RESULTS:
:RESULTS:
: ShapiroResult(statistic=np.float64(0.9630799036343107), pvalue=np.float64(6.119166277975437e-26))
[[file:./.ob-jupyter/e33af25d1903a9a9962a25d0db1fc8dcadff4310.png]]
:END:

#+begin_src jupyter-python :session MiniProject2
np.log(ko["KO"]).plot(title="KO Logvalue: $10000 Invested",
                      ylabel = "Logvalue")
#+end_src

#+RESULTS:
:RESULTS:
: <Axes: title={'center': 'KO Logvalue: $10000 Invested'}, xlabel='Date', ylabel='Logvalue'>
[[file:./.ob-jupyter/371316feaf22f90b281a0bcaf61168e55bd7f208.png]]
:END:

From a visual inspection of the logvalue of an investment in KO, we see that the period between 1975 and 1982 shows promise for lognormal returns, based on intuition alone.
#+begin_src jupyter-python :session MiniProject2
s1,s2 = ("1975-04-01","1982-03-01")

np.log(ko["KO"][s1:s2]).plot(title="KO Logvalue: $10000 Invested",
                      ylabel = "Logvalue")
#+end_src

#+RESULTS:
:RESULTS:
: <Axes: title={'center': 'KO Logvalue: $10000 Invested'}, xlabel='Date', ylabel='Logvalue'>
[[file:./.ob-jupyter/b5a697f2ea154767aca5847c8a0a705c41617c59.png]]
:END:

#+begin_src jupyter-python :session MiniProject2
log_ko[s1:s2].plot(kind="hist",bins=80)
#+end_src

#+RESULTS:
:RESULTS:
: <Axes: ylabel='Frequency'>
[[file:./.ob-jupyter/6db8dbe303bbefc9a1c7564379f0c3ba6aaad7e5.png]]
:END:

Apart from the distribution of logdaily returns looking more favorable than our other assets, we can check the skewness and kurtosis:
#+begin_src jupyter-python :session MiniProject2
print(f"KO Skew: {log_ko[s1:s2].skew()}\nKO Kurtosis: {log_ko[s1:s2].kurtosis()}")
#+end_src

#+RESULTS:
: KO Skew: 0.07501193801330085
: KO Kurtosis: 2.092529284602919

These metrics are the closest to normal distribution so far.
A portfolio of 100% KO might yield logreturns resembling a normal distribution from the time period of 1975-04-01 to 1982-03-01.
Over longer periods of time, it is extremely difficult to find a stock with lognormal returns, due to the long term observation that stocks tend to go up.


To counterbalance any indiosyncratic movement specific to the consumer staple sector which KO operates in, we add a consumer discretionary option to our portfolio with MCD.
#+begin_src jupyter-python :session MiniProject2
mcd = csv_to_series("./MCD.csv")
log_mcd = np.log(1+mcd["MCD Returns"])
#+end_src

#+RESULTS:

#+begin_src jupyter-python :session MiniProject2
w1 = 0.8
w2 = 1-w1
p1 = np.log(1+ w1*ko["KO Returns"] + w2*mcd["MCD Returns"])
p1[s1:s2].plot(kind="hist",bins=80)
#+end_src

#+RESULTS:
:RESULTS:
: <Axes: ylabel='Frequency'>
[[file:./.ob-jupyter/e11c500116c881ecff19d4f509772fe6e9982d0e.png]]
:END:

Even with the addition of a single stock to our portfolio at 20% weight, our distribution gets a big hit of negative skewness, pushing it away from normality.

* An Explanation of more diversity=less normal
As a function of diversification, negative skewness increases in magnitude.
This has an easy empirical explanation: holding more stocks increases the reliability of consistent /positive/ return, pushing the distribution of returns away from normality.
This also explains why distributions of logreturns were less normal the more we coarsened our time view.
Generally, it is more likely for portfolio's returns to be positive over the course of a year rather than the course of a day.

Finding normally distributed returns in stocks is essentially an exercise in arbitrary data mining, and the pattern fails more often than it succeeds.
Though, this is the point of this exercise: the assumption of normal stock returns in various financial models such as Black-Scholes is not borne out in reality, and this illustrates that plainly.
The essence of assuming lognormal returns is simply a convenience to find closed form solutions to option prices, and models incorporating assumptions that reflect reality are much more difficult to work with.

# Local Variables:
# compile-command: "pandoc -s -o MiniProject2.ipynb MiniProject2.org -V header-includes='<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>'"
# eval: (setq-local jupyter-executable (inheritenv (executable-find "jupyter")))
# End
