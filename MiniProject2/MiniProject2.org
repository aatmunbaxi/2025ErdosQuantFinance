#+title: Mini Project 2
#+author: Aatmun Baxi
* Project Statement
** Hypothesis Testing of Standard Assumptions Theoretical Financial Mathematics

In the theory of mathematical finance, it is common to assume the log returns of a stock/index are normally distributed.

Investigate if the log returns of stocks or indexes of your choosing are normally distributed. Some suggestions for exploration include:

1) Test if there are period of times when the log-returns of a stock/index have evidence of normal distribution.
2) Test if removing extremal return data creates a distribution with evidence of being normal.
3) Create a personalized portfolio of stocks with historical log return data that is normally distributed.
4) Test if the portfolio you created in the first mini-project has significant periods of time with evidence of normally distributed log returns.
5) Gather x-number of historical stock data and just perform a normality test on their log return data to see if any of the stocks exhibit evidence of log returns that are normally distributed.
* Commentary
First of all, we choose a particular stock or index to look at.
It is well known that a diversified portfolio of stocks increases the reliability of returns (in excess of 3 month Treasury bills) and reduces volatility.
Therefore, we choose the S&P 500 as our asset, since it is well diversified,  and has the longest running historical total return data that we could find.
* Data Retrieval
:PROPERTIES:
:ARCHIVE_TIME: 2025-06-11 Wed 18:30
:ARCHIVE_FILE: ~/code/2025ErdosQuantFinance/MiniProject2/MiniProject2.org
:ARCHIVE_CATEGORY: MiniProject2
:END:
#+begin_src jupyter-python :exports both :session MiniProject2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

%matplotlib inline
sns.set_style("darkgrid")
#+end_src

#+RESULTS:


#+begin_src jupyter-python :exports both :session MiniProject2
def csv_to_series(csv_path):
    s = pd.read_csv(csv_path)
    s["Date"] = pd.to_datetime(s["Date"])
    s.set_index("Date",inplace = True)
    returns = (s.shift(-1)-s) / s
    returns.columns = [ticker + " Returns" for ticker in s.columns]
    return pd.concat([s, returns],axis=1)

sp500 = csv_to_series("./SP500-returns.csv")
sp500.rename(columns= {"SPYSIM": "SP500", "SPYSIM Returns":"SP500 Returns"},inplace=True)
log_returns = np.log((1+sp500["SP500 Returns"]).dropna())
#+end_src

#+RESULTS:

* Heuristic Checks for Lognormality
As a preliminary look, we can look at the distribution of daily returns.
#+begin_src jupyter-python :exports both :session MiniProject2
log_returns.plot(kind="hist",
                          bins = 100,
                          xlabel="Log Returns",
                          ylabel="Observations",
                          title="Distribution of Daily S&P 500 Returns")
#+end_src

#+RESULTS:
:RESULTS:
: <Axes: title={'center': 'Distribution of Daily S&P 500 Returns'}, xlabel='Log Returns', ylabel='Observations'>
[[file:./.ob-jupyter/205619ec326b7588ff9d17b3cd9544b56a7dbbad.png]]
:END:

A visual inspection is far from sufficient for a test of normality.
We can first "zoom in" to the zero point to viseually cut out the outliers of log returns of absolute magnitude \(> 0.10\).

#+begin_src jupyter-python :exports both :session MiniProject2
log_returns.plot(kind="hist",
                          bins = 100,
                          xlabel="Log Returns",
                          ylabel="Observations",
                          xlim=(-.1,.1),
                          title="Distribution of Daily S&P 500 Returns")
#+end_src

#+RESULTS:
:RESULTS:
: <Axes: title={'center': 'Distribution of Daily S&P 500 Returns'}, xlabel='Log Returns', ylabel='Observations'>
[[file:./.ob-jupyter/77035ca36c035b9c75160cea8ade042dc6f49b24.png]]
:END:

We first note that the distribution appears negatively skewed, with the left tail being fatter than the right tail.
We can verify this empirically
#+begin_src jupyter-python :exports both :session MiniProject2
log_returns.skew()
#+end_src

#+RESULTS:
: np.float64(-0.43940576052749036)

Indeed, the distribution is negatively skewed.
The value of skewness alone gives us a hint that the data are not normally distributed.

#+begin_src jupyter-python :exports both :session MiniProject2
pd.DataFrame(log_returns).boxplot()
#+end_src

#+RESULTS:
:RESULTS:
: <Axes: >
[[file:./.ob-jupyter/436f0c75c4420456e3fce320645066acb1e7ad0d.png]]
:END:

The vast majority of the log return values seem to lie in the interval \((-0.10,0.10)\).
This is the range we will inspect.
#+begin_src jupyter-python :exports both :session MiniProject2
clamped=pd.DataFrame(log_returns[(log_returns <= 0.1) & (log_returns >= -0.1) ])
clamped.boxplot()
#+end_src

#+RESULTS:
:RESULTS:
: <Axes: >
[[file:./.ob-jupyter/3d744855e14608e4a8b65bf3d052745f88b83aa7.png]]
:END:

The boxplot still shows signs of negative skewness, but we can check if the magnitude of skewness is less than what we started with.
#+begin_src jupyter-python :exports both :session MiniProject2
clamped.skew()
#+end_src

#+RESULTS:
: SP500 Returns   -0.330623
: dtype: float64

The skewness does decrease in magnitude, but its value still indicates a distribution far from normal.
It seems daily returns are too negatively skewed to recover a distribution that is normal.

Instead, we can coarsen our return periods to weekly, monthly, and yearly returns to see if they exhibit different behaviours.
We should expect this to be an improvement on log-daily returns, since the reliability of stock returns tends to increase the longer the time period you look at.

#+begin_src jupyter-python :exports both :session MiniProject2
weekly_logs = np.log((1+sp500["SP500 Returns"]).groupby(pd.Grouper(freq="W-MON")).agg("prod"))
weekly_logs.plot(kind="hist",bins = 60,
                 title="Weekly log Returns",
                 xlabel="Log Returns")
#+end_src

#+RESULTS:
:RESULTS:
: <Axes: title={'center': 'Weekly log Returns'}, xlabel='Log Returns', ylabel='Frequency'>
[[file:./.ob-jupyter/535d83082e2378e20fc386b198cca1dcf5268ee2.png]]
:END:

#+begin_src jupyter-python :exports both :session MiniProject2
weekly_logs.skew()
#+end_src

#+RESULTS:
: np.float64(-0.8428780928389739)

On the collection of all the data, the skewness of the weekly log returns is less skewed than the daily log returns, but still skewed in the same direction.
We can coarsen the view to further to monthly returns.
#+begin_src jupyter-python :exports both :session MiniProject2
monthly_logs = np.log((1+sp500["SP500 Returns"]).groupby(pd.Grouper(freq="ME")).agg("prod"))
monthly_logs.plot(kind="hist",bins = 60,
                 title="Monthly log Returns",
                 xlabel="Log Returns")
#+end_src

#+RESULTS:
:RESULTS:
: <Axes: title={'center': 'Monthly log Returns'}, xlabel='Log Returns', ylabel='Frequency'>
[[file:./.ob-jupyter/dba3aa8a5210f398694841ce08dadbf3d9e7bbc2.png]]
:END:
#+begin_src jupyter-python :exports both :session MiniProject2
monthly_logs.skew()
#+end_src

#+RESULTS:
: np.float64(-0.564938766290267)

Even monthy returns are negatively skewed.
#+begin_src jupyter-python :exports both :session MiniProject2
yearly_logs = np.log((1+sp500["SP500 Returns"]).groupby(pd.Grouper(freq="YE")).agg("prod"))
yearly_logs.plot(kind="hist",bins = 60,
                 title="log Yearly Returns",
                 xlabel="Log Returns")
#+end_src

#+RESULTS:
:RESULTS:
: <Axes: title={'center': 'log Yearly Returns'}, xlabel='Log Returns', ylabel='Frequency'>
[[file:./.ob-jupyter/f8d4426c56599a2559867a4936d2eabc7d3b6861.png]]
:END:
#+begin_src jupyter-python :exports both :session MiniProject2
yearly_logs.skew()
#+end_src

#+RESULTS:
: np.float64(-0.918299847545862)

Even at time scales such as a year, returns of a diverse portfolio of US stocks shows little evidence of being normal.
* Formal Tests for Normality
So far, our tests for normality has been heuristic in nature.
There are formal tests for normality such as she Shapiro-Wilk test, which we can employ.
Below is the resulting \(p\) values extracted from the test, where the null hypothesis is that the data are normally distributed.
#+begin_src jupyter-python :exports both :session MiniProject2
from scipy.stats import shapiro
results = {str(x): float(shapiro(x)[1]) for x in [log_returns,weekly_logs, monthly_logs, yearly_logs]}
print(f"Shapiro-Wilk p-values:\n {results}")
#+end_src

#+RESULTS:
: Shapiro-Wilk p-values:
:  {'Date\n1885-03-20   -0.007865\n1885-03-23   -0.010866\n1885-03-24    0.008595\n1885-03-25    0.008316\n1885-03-26    0.000630\n                ...   \n2025-05-22   -0.006845\n2025-05-23    0.020581\n2025-05-27   -0.005798\n2025-05-28    0.003943\n2025-05-29   -0.001115\nName: SP500 Returns, Length: 35112, dtype: float64': 3.818543836005726e-93, 'Date\n1885-03-23   -0.018731\n1885-03-30    0.008426\n1885-04-06   -0.011074\n1885-04-13    0.038922\n1885-04-20    0.000452\n                ...   \n2025-05-05    0.008068\n2025-05-12    0.048979\n2025-05-19    0.010208\n2025-05-26   -0.002857\n2025-06-02   -0.002970\nFreq: W-MON, Name: SP500 Returns, Length: 7316, dtype: float64': 1.178035812534928e-52, 'Date\n1885-03-31   -0.009045\n1885-04-30    0.029342\n1885-05-31   -0.026852\n1885-06-30    0.003949\n1885-07-31    0.091858\n                ...   \n2025-01-31    0.022285\n2025-02-28   -0.023628\n2025-03-31   -0.036759\n2025-04-30   -0.004388\n2025-05-31    0.053962\nFreq: ME, Name: SP500 Returns, Length: 1683, dtype: float64': 1.2008592564647532e-28, 'Date\n1885-12-31    0.278762\n1886-12-31    0.079888\n1887-12-31   -0.043394\n1888-12-31    0.087422\n1889-12-31    0.101203\n                ...   \n2021-12-31    0.273082\n2022-12-31   -0.209597\n2023-12-31    0.232158\n2024-12-31    0.226321\n2025-12-31    0.011472\nFreq: YE-DEC, Name: SP500 Returns, Length: 141, dtype: float64': 0.00021204832741660105}
: /nix/store/8f9zfpbmybfl09aq4a9nzp8a9gwgqjbf-python3.12-scipy-1.15.3/lib/python3.12/site-packages/scipy/stats/_axis_nan_policy.py:586: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 35112.
:   res = hypotest_fun_out(*samples, **kwds)
: /nix/store/8f9zfpbmybfl09aq4a9nzp8a9gwgqjbf-python3.12-scipy-1.15.3/lib/python3.12/site-packages/scipy/stats/_axis_nan_policy.py:586: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 7316.
:   res = hypotest_fun_out(*samples, **kwds)

In every performance of the Shapiro-Wilk test, the resulting \(p\) value is decidedly below \(0.05\), so in every case we reject the null hypothesis that the data are normally distributed.

On the other hand, the =normaltest= from =scipy.stats= uses skewness and kurtosis to compare against a normal distribtution.

#+begin_src jupyter-python :exports both :session MiniProject2
from scipy.stats import normaltest
print(f"p-values; skewness-kurtosis test:\n{normaltest(pd.concat([log_returns, weekly_logs, monthly_logs,yearly_logs],axis=1),nan_policy='omit',axis=0).pvalue}")
#+end_src

#+RESULTS:
: p-values; skewness-kurtosis test:
: [0.00000000e+00 0.00000000e+00 2.01874396e-72 5.74204997e-06]

In this test, too, there is sufficient evidence to reject the hypothesis that the data are normaly distributed at all sampled time scales.

* Testing a Particular Bull Market
Because a of the pervasive observation that stock returns are negatively skewed, we might have better luck finding evidence of normality of stock returns during bull marketsâ€”periods where the market trends upward without a 20% drop from its high.
Periods of volatili
We examine the longest bull market in US history: the period between December 1987 and March 2000
#+begin_src jupyter-python :exports both :session MiniProject2
start, end = ("1987-12-01","2000-03-01")
log_returns[start:end].plot(kind="hist",bins=50,xlabel="Log Daily Returns")

#+end_src

#+RESULTS:
:RESULTS:
: <Axes: xlabel='Log Daily Returns', ylabel='Frequency'>
[[file:./.ob-jupyter/4562bfd97122c54278ffd2b558102cb4786104d5.png]]
:END:

Looking at the distribution of daily returns, we can already see a thinning of the tails, though the daily returns still appear negatively distributed.
We investigate the \(p\) value of the formal Shapiro-Wilk test on the monthly returns during this bull market.
#+begin_src jupyter-python :exports both :session MiniProject2
print(f"p = {shapiro(monthly_logs[start:end])[1]}")
#+end_src

#+RESULTS:
: p = 0.08925705296206543

With a tolerance of \(p = 0.05\), there is not sufficient evidence to reject the null hypothesis that the data is normally distributed.
Thus, there is possible evidence of the log monthly returns of the S&P 500 being normally distributed during the 1987-2000 bull market.

Let us investigate the second longest bull market spanning from March 2009 to February 2020.
#+begin_src jupyter-python :exports both :session MiniProject2
start, end = ("2009-03-01", "2020-02-01")
log_returns[start:end].plot(kind="hist",bins=50,xlabel="Log Daily Returns",
                            title="Log Daily Returns Mar 2009-Feb 2020")
#+end_src

#+RESULTS:
:RESULTS:
: <Axes: title={'center': 'Log Daily Returns Mar 2009-Feb 2020'}, xlabel='Log Daily Returns', ylabel='Frequency'>
[[file:./.ob-jupyter/5b4f189bacc8d07a251a1befbe4e44cfb7cc1e16.png]]
:END:

This time, the left tail is much fatter than the previous bull market under examination.
#+begin_src jupyter-python :exports both :session MiniProject2
print(f"p = {shapiro(monthly_logs[start:end])[1]}")
#+end_src

#+RESULTS:
: p = 0.0011705343595598472

As the visual inspection suggested, we cannot conclude normality of the monthly returns in this period.


** Conclusion
We can conclude that it is very difficult to find periods of time and scales of time where stock returns are normally distributed, even when volatility is controlled by using a diversified portfolio.
This suggests that the assumption of normal stock returns used in the Black-Scholes model does not reflect reality.
It still serves the useful purpose of helping extract closed-form equation
* A Portfolio with Normal Return
For some commentary, we should not expect it to be easy to construct a portfolio of stocks (i.e. *equities*) with lognormal returns over a significant period of time.
Equities are inherently riskier than other financial assets like bonds, and show fatter tails in distributions of historical returns on virtually all time scales.
One typically reduces the volatility of a portfolio of stocks by allocating to "safer" kinds of stocks (e.g. consumer staples, utilities) or by moving away from stocks altogether and using bonds.
Since we are interested in stocks only, we will work within the confines of equities.

The empirical evidence of more diversification = less volatility is too overwhelming for us to escape this framework, so we will continue to hold a diverse  portfolio of equities.
Notably, we want to move away from holding market cap weights (like with the S&P 500), since we have demonstrated empirically that such a portfolio shows little evidence of lognormal returns over long periods of time.

We will be counterbalancing the risky S&P 500 with utilities and consumer staples, which are sectors commonly thought to be safer than other types of stocks.
#+begin_src jupyter-python :exports both :session MiniProject2
xlu = csv_to_series("./utilities.csv").dropna()
xlp = csv_to_series("./staples.csv").dropna()
#+end_src

#+RESULTS:

#+begin_src jupyter-python :exports both :session MiniProject2
np.log(pd.concat([xlu["Utilities"],xlp["Staples"]]
                 ,axis=1).iloc[::5,:]).plot(title="Log value")
#+end_src

#+RESULTS:
:RESULTS:
: <Axes: title={'center': 'Log value'}, xlabel='Date'>
[[file:./.ob-jupyter/eb3e2594ac412436015d05babfcae8716274c256.png]]
:END:

#+begin_src jupyter-python :exports both :session MiniProject2
log_xlu = np.log(1+xlu["Utilities Returns"])
log_xlp = np.log(1+xlp["Staples Returns"])
pd.concat([log_xlu,log_xlp],axis=1).plot(kind="hist",layout=(2,1),
                                         subplots=True,
                                         bins=70,
                                         xlabel = "Daily Log Returns",
                                         title = "Distribution of Daily Log Returns")
#+end_src

#+RESULTS:
:RESULTS:
: array([[<Axes: xlabel='Daily Log Returns', ylabel='Frequency'>],
:        [<Axes: xlabel='Daily Log Returns', ylabel='Frequency'>]],
:       dtype=object)
[[file:./.ob-jupyter/619df6b3ee5ac84e5c46c722cd0c7193208686d1.png]]
:END:
#+begin_src jupyter-python :exports both :session MiniProject2
pd.concat([log_xlu,log_xlp],axis=1).skew()
#+end_src

#+RESULTS:
: Utilities Returns   -0.179888
: Staples Returns     -0.495754
: dtype: float64

Utilities display a distribution of daily returns less negatively skewed than the S&P 500.

#+begin_src jupyter-python :exports both :session MiniProject2
xlu_logmonthly = log_xlu.groupby(pd.Grouper(freq="ME")).agg("sum")
xlp_logmonthly = log_xlp.groupby(pd.Grouper(freq="ME")).agg("sum")
xlu_logweekly= log_xlu.groupby(pd.Grouper(freq="W-MON")).agg("sum")
xlp_logweekly= log_xlp.groupby(pd.Grouper(freq="W-MON")).agg("sum")
xlu_logyearly= log_xlu.groupby(pd.Grouper(freq="YE")).agg("sum")
xlp_logyearly= log_xlp.groupby(pd.Grouper(freq="YE")).agg("sum")
#+end_src

#+RESULTS:

#+begin_src jupyter-python :exports both :session MiniProject2
pd.concat([xlu_logweekly,xlp_logweekly],axis=1).plot(kind="hist",subplots=True,bins=80)
#+end_src

#+RESULTS:
:RESULTS:
: array([<Axes: ylabel='Frequency'>, <Axes: ylabel='Frequency'>],
:       dtype=object)
[[file:./.ob-jupyter/5891e1d6591772f73e2c0ac7c890a06670f803dc.png]]
:END:

#+begin_src jupyter-python :exports both :session MiniProject2
# xlp["Staples Returns"]["1990-01-01":].plot(kind="hist",
#                                            bins=50,
#                                            title="Consumer Staples logdaily Returns",
#                                            xlabel="Log Returns")
plt.title("Distribution of logdaily Returns ")
plt.xlabel("")
sns.histplot(xlp["Staples Returns"]["1990-01-01":])
#+end_src

#+RESULTS:
:RESULTS:
: <Axes: title={'center': 'Distribution of logdaily Returns '}, xlabel='Staples Returns', ylabel='Count'>
[[file:./.ob-jupyter/1ccb76d969892f50d64cebe35b530fbe6a7e35b2.png]]
:END:

# Local Variables:
# compile-command: "pandoc -s -o MiniProject2.ipynb MiniProject2.org -V header-includes='<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>'"
# eval: (setq-local jupyter-executable (inheritenv (executable-find "jupyter")))
# End:
